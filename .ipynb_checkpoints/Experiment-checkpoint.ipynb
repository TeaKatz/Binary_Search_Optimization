{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/panuthep/binary_search_optimization\" target=\"_blank\">https://app.wandb.ai/panuthep/binary_search_optimization</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/panuthep/binary_search_optimization/runs/thyve35h\" target=\"_blank\">https://app.wandb.ai/panuthep/binary_search_optimization/runs/thyve35h</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "W&B Run: https://app.wandb.ai/panuthep/binary_search_optimization/runs/thyve35h"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project=\"binary_search_optimization\", name=\"verysmall_unbalance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_DIRS = \"./Datasets/dataset_verysmall.pkl\"\n",
    "MAX_MONSTER_NUM = 1000\n",
    "MONSTER_HP_COLUMNS = [\"monster_hp_\" + str(num) for num in range(1, MAX_MONSTER_NUM + 1)]\n",
    "FEATURES = [\"focus_damage\", \"aoe_damage\", *MONSTER_HP_COLUMNS]\n",
    "TARGET = [\"attack_num\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_pickle(DATASET_DIRS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error generating diff: Command '['git', 'diff', '--submodule=diff', 'HEAD']' timed out after 5 seconds\n",
      "/anaconda3/envs/dev/lib/python3.7/site-packages/plotly/matplotlylib/mpltools.py:368: MatplotlibDeprecationWarning:\n",
      "\n",
      "\n",
      "The is_frame_like function was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for col in [\"focus_damage\", \"aoe_damage\", \"attack_num\"]:\n",
    "    plt.hist(dataset[col])\n",
    "    wandb.log({col: plt})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = train_test_split(dataset, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.linspace(dataset[TARGET].to_numpy().min(), dataset[TARGET].to_numpy().max(), 100, dtype=int)\n",
    "Y_bin = np.digitize(dataset[TARGET].to_numpy(), bins)\n",
    "\n",
    "train_set, test_set = train_test_split(dataset, random_state=42, shuffle=True, stratify=Y_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train = train_set[FEATURES].to_numpy(), train_set[TARGET].to_numpy()\n",
    "X_test, Y_test = test_set[FEATURES].to_numpy(), test_set[TARGET].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(68250, 22750)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train), len(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaler = MinMaxScaler()\n",
    "X_train_scaled = X_scaler.fit_transform(X_train.astype(np.float32))\n",
    "X_test_scaled = X_scaler.transform(X_test.astype(np.float32))\n",
    "\n",
    "Y_scaler = MinMaxScaler()\n",
    "Y_train_scaled = Y_scaler.fit_transform(Y_train.astype(np.float32))\n",
    "Y_test_scaled = Y_scaler.transform(Y_test.astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(Y_scaler, \"./Save/Y_scaler.pkl\")\n",
    "joblib.dump(X_scaler, \"./Save/X_scaler.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LeakyReLU\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.losses import MAE\n",
    "from utilities import LearningRateFinder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error generating diff: Command '['git', 'diff', '--submodule=diff', 'HEAD']' timed out after 5 seconds\n"
     ]
    }
   ],
   "source": [
    "wandb.config.network_depth = 1\n",
    "wandb.config.network_width = 16\n",
    "wandb.config.activation = \"LeakyReLU\"\n",
    "wandb.config.optimizer = \"Adam\"\n",
    "wandb.config.loss = \"MAE\"\n",
    "wandb.config.epochs = 100\n",
    "wandb.config.batch_size = 32\n",
    "wandb.config.validation_split = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def history_plot(history):\n",
    "    x = list(range(len(history.history[\"loss\"])))\n",
    "    loss = history.history[\"loss\"]\n",
    "    val_loss = history.history[\"val_loss\"]\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.title(\"loss\")\n",
    "    plt.plot(x, loss)\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.title(\"val_loss\")\n",
    "    plt.plot(x, val_loss)\n",
    "    \n",
    "def losses_plot(Y_true, Y_pred):\n",
    "    losses = MAE(Y_true, Y_pred)\n",
    "    plt.scatter(Y_pred, losses)\n",
    "    plt.show()\n",
    "    \n",
    "def prediction_distribution(pred):\n",
    "    plt.hist(pred, bins=100)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = [X_train.shape[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequenceDense(Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden_layers = []\n",
    "        for i in range(wandb.config.network_depth):\n",
    "            self.hidden_layers.append(Dense(wandb.config.network_width, activation=LeakyReLU()))\n",
    "        \n",
    "        self.dense_1 = Dense(16, activation=LeakyReLU())\n",
    "        self.output_layer = Dense(1, activation=\"relu\")\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        output = self.dense_1(inputs)\n",
    "        output = self.dense_2(output)\n",
    "        \n",
    "        return output\n",
    "\n",
    "class NonSequenceDense(Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.dense_1 = Dense(16, activation=\"relu\")\n",
    "        self.dense_2 = Dense(1, activation=\"relu\")\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        hps, damages = tf.split(inputs, [1000, 2], axis=1)\n",
    "        output = self.dense_1(hps)\n",
    "        output = tf.concat([output, damages], axis=1)\n",
    "        output = self.dense_2(output)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save or load initial model, so every time, we start with the same init model\n",
    "model = SequenceDense()\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss=\"mae\")\n",
    "# model.save_weights(\"./Save/Model_initial/model_1024\")\n",
    "model.load_weights(\"./Save/Model_initial/model_1024\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_finder = LearningRateFinder(model)\n",
    "lr_finder.find((X_train_scaled, Y_train_scaled), start_lr=1e-10, epochs=20)\n",
    "lr_finder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_finder.plot(start=150000, end=250000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_finder.lrs[200000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = SequenceDense()\n",
    "model.load_weights(\"./Save/Model_initial/model_1024\")\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=lr_finder.lrs[180000]), loss=\"mae\")\n",
    "history = model.fit(X_train_scaled, Y_train_scaled, epochs=500, batch_size=32, validation_split=0.2, verbose=1)\n",
    "\n",
    "history_plot(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test_scaled, Y_test_scaled, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inbalance dataset is highly possible due to the following prediction distriburion.\n",
    "pred = model.predict(X_train_scaled)\n",
    "prediction_distribution(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(Y_train_scaled)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"./Save/Model_without_decay/model_1024\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SequenceDense()\n",
    "model.load_weights(\"./Save/Model_without_decay/model_1024\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inbalance dataset is highly possible due to the following prediction distriburion.\n",
    "pred = model.predict(X_train_scaled)\n",
    "prediction_distribution(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses_plot(Y_train_scaled, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
